{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d6713b-75b6-42fa-a95c-cf261a74e017",
   "metadata": {},
   "source": [
    "# Calculate Spatial and temporal NME scores, then calculate ensemble weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5d96de-b63d-4ede-82b1-7db867004357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Functions import *\n",
    "from Global_Variables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2545d1-f8cb-448f-aeae-22ef2e5c2d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_df = add_global(pd.read_pickle(os.path.join(RESULTS_PATH, 'AR6_obs_df.pkl')))\n",
    "obsclim_df = add_global(pd.read_pickle(os.path.join(RESULTS_PATH, 'AR6_obsclim_df.pkl')))\n",
    "counterclim_df = add_global(pd.read_pickle(os.path.join(RESULTS_PATH, 'AR6_counterclim_df.pkl')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824eb26-bba9-4342-89ff-c006b48dc067",
   "metadata": {},
   "source": [
    "## Calculate Error scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c082e-211f-4bc3-a920-85e29058c0de",
   "metadata": {},
   "source": [
    "### Spatial NME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852011b-7fd1-42b6-8683-58ec7ba582e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') # Surpress some unimportant warnings\n",
    "rng = np.random.default_rng(SEED)\n",
    "start_year, end_year = 2003, 2019\n",
    "NME_scores = pd.DataFrame(index=pd.MultiIndex.from_product([obs_dict.keys(), ('$NME_1$', '$NME_3$')], names=['Observation', 'NME']), columns=obsclim_df.columns.unique(level='Model'))\n",
    "\n",
    "for obsname in NME_scores.index.unique(level='Observation'):\n",
    "    obs = constrain_time(iris.load_cube(obs_dict[obsname]), start_year, end_year)\n",
    "    for modelname in NME_scores.columns.unique(level='Model'):\n",
    "        model = constrain_time(preprocess_model(iris.load_cube(model_dict[modelname]['obsclim']), modelname), start_year, end_year)\n",
    "        NME_scores.loc[(obsname), modelname] = [NME1(obs, model), NME3(obs, model)]\n",
    "\n",
    "warnings.filterwarnings('default')   \n",
    "NME_scores.to_pickle(os.path.join(RESULTS_PATH, 'NME_scores_spatial.pkl'))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d2f83-8320-42d3-a9ce-d1e96f504e76",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1394f70-16a4-476d-8e75-9acfcf5d910f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "start_year, end_year = 2003, 2019\n",
    "obs_double_df = constrain_time(obs_df, start_year, end_year).stack(sort=False).swaplevel(0, 1).sort_index()\n",
    "obs_yearly_double_df = to_annual(constrain_time(obs_df, start_year, end_year)).stack(sort=False).swaplevel(0, 1).sort_index()\n",
    "\n",
    "obsclim_double_df = pd.concat([constrain_time(obsclim_df, start_year, end_year)]*2)\n",
    "obsclim_yearly_double_df = pd.concat([to_annual(constrain_time(obsclim_df, start_year, end_year))]*2)\n",
    "\n",
    "RMSE_RA_monthly_df = pd.DataFrame(index=['RMSE'], columns=obsclim_df.columns)\n",
    "RMSE_RA_annual_df = pd.DataFrame(index=['RMSE'], columns=obsclim_df.columns)\n",
    "\n",
    "for regionname, modelname in RMSE_RA_monthly_df.columns:\n",
    "    obs_RA = obs_double_df.loc[slice(None), regionname].groupby('Observation', observed=True).apply(lambda df: relative_anomaly(df)).droplevel(1).droplevel('Observation')\n",
    "    model_RA = obsclim_double_df.loc[slice(None), regionname].stack('Model').groupby('Model', observed=True).apply(lambda df: relative_anomaly(df)).droplevel(2)\n",
    "    RMSE_RA_monthly_df.loc['RMSE', (regionname)] = model_RA.groupby('Model', observed=False).apply(lambda model: ((obs_RA - model.droplevel('Model'))**2).mean()**.5).values\n",
    "    \n",
    "    obs_yearly_RA = obs_yearly_double_df.loc[slice(None), regionname].groupby('Observation', observed=True).apply(lambda df: relative_anomaly(df)).droplevel(1).droplevel('Observation')\n",
    "    model_yearly_RA = obsclim_yearly_double_df.loc[slice(None), regionname].stack('Model').groupby('Model', observed=True).apply(lambda df: relative_anomaly(df)).droplevel(2)\n",
    "    RMSE_RA_annual_df.loc['RMSE', (regionname)] = model_yearly_RA.groupby('Model', observed=False).apply(lambda model: ((obs_yearly_RA - model.droplevel('Model'))**2).mean()**.5).values\n",
    "    \n",
    "RMSE_RA_monthly_df.to_pickle(os.path.join(RESULTS_PATH, 'RMSE_RA_monthly.pkl'))\n",
    "RMSE_RA_annual_df.to_pickle(os.path.join(RESULTS_PATH, 'RMSE_RA_annual.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676698c-3e4a-4cd9-b64f-0802ce137b21",
   "metadata": {},
   "source": [
    "## Optimal sigmaD (1000 times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b162237-182e-498a-b086-9ff40d5a9fb7",
   "metadata": {},
   "source": [
    "### Temporal NME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f77e85-51dd-419a-add6-f6e7e763fd55",
   "metadata": {},
   "source": [
    "Calculate __for__ each region, __for__ each of the the two observations the temporal NME3 scores (annual and ranked) of the _fire models_ and the _reference model_ (randomly resampled observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1e36bf-e107-447a-92f9-ffc828477aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "start_year, end_year = 2003, 2019\n",
    "index = pd.MultiIndex.from_product([obs_dict.keys(), ('NME3_ranked', 'NME3_annual')], names=['Observation', 'NME'])\n",
    "NME_scores = pd.DataFrame(index=index, columns=obsclim_df.columns, dtype=np.float32)\n",
    "\n",
    "columns = obsclim_df.columns.unique(level='Region')\n",
    "NME_ref_scores = pd.DataFrame(index=index, columns=columns, dtype=np.float32)\n",
    "\n",
    "for regionname, modelname in NME_scores.columns:\n",
    "    obs = constrain_time(select_region(obs_df, regionname), start_year, end_year)\n",
    "    model = constrain_time(select_region(select_models(obsclim_df, modelname), regionname), start_year, end_year)\n",
    "       \n",
    "    for obs_name in NME_scores.index.unique(level='Observation'):\n",
    "        obs_select = select_models(obs, obs_name)\n",
    "        obs_series, model_series = obs_select[(regionname, obs_name)], model[(regionname, modelname)]\n",
    "        obs_annual_series, model_annual_series = to_annual(obs_select)[(regionname, obs_name)], to_annual(model)[(regionname, modelname)]\n",
    "        \n",
    "        random_obs = pd.Series(rng.choice(obs_select.values.flatten(), size=len(obs.index), replace=False), index=obs_select.index)\n",
    "        \n",
    "        NME_scores.loc[(obs_name), (regionname, modelname)] = (NME3_temporal(obs_series.sort_values(), model_series.sort_values()), NME3_temporal(obs_annual_series, model_annual_series))\n",
    "        NME_ref_scores.loc[(obs_name), (regionname)] = [NME3_temporal(obs_series.sort_values(), random_obs), NME3_temporal(to_annual(obs_series), to_annual(random_obs))]\n",
    "\n",
    "NME_scores.to_pickle(os.path.join(RESULTS_PATH, 'NME_scores_temporal.pkl'))\n",
    "NME_ref_scores.to_pickle(os.path.join(RESULTS_PATH, 'NME_ref_scores_temporal.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f51c740-8db1-45ab-af1c-a861d159674c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_double_df = constrain_time(obs_df, start_year, end_year).stack(sort=False).swaplevel(0, 1).sort_index()\n",
    "obsclim_double_df = pd.concat([constrain_time(obsclim_df, start_year, end_year)]*2)\n",
    "RMSE_RA_monthly_df = pd.DataFrame(index=obsclim_df.columns.unique(level='Region'), columns=obsclim_df.columns.unique(level='Model'))\n",
    "\n",
    "for regionname, modelname in obsclim_double_df.columns:\n",
    "    obs_series = obs_double_df.loc[slice(None), regionname]\n",
    "    model_series = obsclim_double_df.loc[slice(None), (regionname, modelname)]\n",
    "    obs_RA = (obs_series-obs_series.mean())/obs_series.mean()\n",
    "    model_RA = (model_series-model_series.mean())/model_series.mean()\n",
    "    RMSE_RA_monthly_df.loc[regionname, modelname] = ((obs_RA.values - model_RA.values)**2).mean()**.5\n",
    "    \n",
    "RMSE_RA_monthly_df = RMSE_RA_monthly_df.astype(np.float32)\n",
    "RMSE_RA_monthly_df.to_pickle(os.path.join(RESULTS_PATH, 'RMSE_RA.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51d7eb1-c57f-460a-b92e-7a4dcf1cf92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sigmaD = 10\n",
    "sigmaDs = pd.Series(np.logspace(0.01, np.log2(max_sigmaD+1), base=2,num=500, dtype=np.float32)-1, name='sigmaD')\n",
    "model_weights = pd.DataFrame(np.nan, index=sigmaDs, columns=obsclim_df.columns, dtype=np.float64)\n",
    "\n",
    "distances = pd.to_numeric((NME_scores/NME_scores.T.groupby(level='Region', sort=False, observed=True).median().T).sum())\n",
    "for sigmaD in model_weights.index:\n",
    "    weights_not_normalized = (-distances/sigmaD).apply(lambda x: np.exp(x))\n",
    "    weights_normalized = weights_not_normalized/weights_not_normalized.groupby(level=('Region'), sort=False, observed=True).sum()\n",
    "    model_weights.loc[(sigmaD), slice(None)] = weights_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ec76f3-e6cc-485b-b3f3-d64d9b152ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [59:34<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "obsclim_pd = constrain_time(obsclim_df, start_year, end_year)\n",
    "obsclim_pd_RA = relative_anomaly(pd.concat([obsclim_pd]*2))\n",
    "obs_pd_RA_df = relative_anomaly(constrain_time(obs_df, start_year, end_year)).stack(sort=False).swaplevel(0, 1).sort_index().droplevel('Observation')\n",
    "\n",
    "num_loops = 1000\n",
    "fraction_correct = []\n",
    "\n",
    "for idx in tqdm(range(num_loops)):\n",
    "    obsclim_pd_RA_added_noise = add_error(obsclim_pd_RA, seed=idx, error=RMSE_RA_monthly_df.stack())\n",
    "    fraction_correct_idx = []\n",
    "    \n",
    "    for sigmaD in sigmaDs:\n",
    "        weights = model_weights.loc[sigmaD]\n",
    "        weighted_average = (obsclim_pd_RA_added_noise*weights).T.groupby(level='Region', sort=False, observed=True).sum().T\n",
    "        \n",
    "        variance = obsclim_pd_RA_added_noise.subtract(weighted_average, axis=0)**2\n",
    "        weighted_variance = variance*weights\n",
    "        weighted_variance_regional = weighted_variance.T.groupby(level='Region', sort=False, observed=True).sum().T\n",
    "        weighted_stddev = np.sqrt(weighted_variance_regional)\n",
    "        \n",
    "        upper_bound = weighted_average+1.96*weighted_stddev\n",
    "        lower_bound = weighted_average-1.96*weighted_stddev\n",
    "        \n",
    "        fraction_correct_idx_sigmaD = ((obs_pd_RA_df <= upper_bound) & (obs_pd_RA_df >= lower_bound)).mean(axis=0)\n",
    "        fraction_correct_idx_sigmaD.name = sigmaD\n",
    "        fraction_correct_idx.append(fraction_correct_idx_sigmaD)\n",
    "        \n",
    "    fraction_correct_idx = pd.concat(fraction_correct_idx, axis=1).T\n",
    "    fraction_correct_idx.index.name = 'sigmaD'\n",
    "    fraction_correct.append(fraction_correct_idx)\n",
    "    \n",
    "fraction_correct = pd.concat(fraction_correct, keys=np.arange(num_loops), names=['idx', 'sigmaD'])\n",
    "fraction_correct.to_pickle(os.path.join(RESULTS_PATH, 'fraction_correct.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3dee54-ce10-45ab-8db5-bc1cf2d37949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the fraction of correct values to a boolean indicating whetehr it's above 0.95 (True) or not (False).\n",
    "# Then groupby idx and region.\n",
    "fraction_correct_over_95 = fraction_correct>0.95\n",
    "fraction_correct_over_95_grouped = fraction_correct_over_95.stack().unstack('sigmaD').groupby(['idx', 'Region'], sort=False, observed=False)\n",
    "# For each idx, region combination take the idxmax (first idx (=sigmaD) at which we find the max value (True)), if none of the values are True then we take np.nan instead\n",
    "optimal_sigmaDs = fraction_correct_over_95_grouped.apply(lambda x: x.idxmax(axis=1).values.item() if x.any(axis=1).values.item() else np.nan)\n",
    "optimal_sigmaDs = optimal_sigmaDs.unstack('Region')\n",
    "\n",
    "optimal_weights = pd.DataFrame(index=optimal_sigmaDs.index, columns=model_weights.columns, dtype=np.float32)\n",
    "for regionname in optimal_sigmaDs.columns:\n",
    "    region_weights = model_weights.loc[(optimal_sigmaDs.loc[slice(None), regionname].dropna()), (regionname)]\n",
    "    optimal_weights.loc[(~optimal_sigmaDs.loc[slice(None), regionname].isna()), (regionname)] = region_weights.values.astype(np.float32)\n",
    "\n",
    "optimal_weights.index = optimal_weights.index.astype(np.int16)\n",
    "optimal_weights.to_pickle(os.path.join(RESULTS_PATH, 'optimal_weights.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
